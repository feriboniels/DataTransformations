import requests
import os
import json
from datetime import date, timedelta
from pyspark.sql.functions import split, col

# To import a Weather (provided by national authorities) file into local folder:

url = "https://smn.conagua.gob.mx/tools/GUI/webservices/?method=1"
response = requests.get(url)
with open("/home/jovyan/archivo.gz", "wb") as f:
	f.write(response.content) 

os.system(f'gunzip archivo.gz') 

print(os.getcwd())

gunzip archivo.gz

#json_file_path = "dbfs:/FileStore/tables/my_data.json" 

json_file_path = "/home/jovyan/archivo"

# Read the CSV file into a DataFrame
df = spark.read.json(json_file_path, multiLine=True)

df.createTempView("tiempo")

df1=spark.sql("select * from tiempo where  lat between 21.84 and 21.85 and lon between -102 and -102.3")




def get_word_details(word):
    language = ""
    headers = { }
    url = f"https://www.inegi.org.mx/app/api/denue/v1/consulta/buscar/restaurantes/21.85717833,-102.28487238/300/4d1b4bfe-84b2-478d-853b-e83106a4be6e"
    response = requests.get(url, headers=headers)
    return response

if __name__ == "__main__":
    response = get_word_details("cogent")
    print(response.text)

json_rdd = sc.parallelize([response.text])
df = spark.read.json(json_rdd)
df.createOrReplaceTempView('info')

dfp2= spark.sql("select Calle,Num_Exterior, Ubicacion ,Nombre, Latitud ,Longitud from info")
df2=dfp2.withColumn('Ciudad',split(dfp2['Ubicacion'],',').getItem(0)).drop('Ubicacion')

ds=(str(date.today()- timedelta(days=1)).replace("-","")+"T00")
dss= f'\"{ds}\"'

query = f"""
select dloc ,desciel, lat, lon ,nes, tmax,tmin 
from tiempo where dloc ={dss} 
and  lat between 21.84 and 21.85 
and lon between -102 and -102.3 
"""

df1 =spark.sql(query)
result_df = df1.crossJoin(df2)

result_df.write.format("parquet").mode("append").saveAsTable("geodata")
